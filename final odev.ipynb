{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b361667-3266-4021-a73b-6ad5c549e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/usame/Downloads/lemmatized_data.xls\")\n",
    "query_text = df.iloc[4][\"text\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db8ddc37-5db0-4339-a8b8-80f7bfe36e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem = pd.read_csv(\"tfidf_lemmatized.csv\")\n",
    "df_stem = pd.read_csv(\"tfidf_stemmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62756f8b-c2d1-4e92-bc15-a8c317434516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\usame\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\usame\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\usame\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\usame\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ef668d1-50a5-4a42-ba5d-3a84af4c5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_vector = df_lem.iloc[4].values.reshape(1, -1)  # same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa249aba-231b-45a3-acf5-a43ccfb13f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            text\n",
      "6           harry potter collection harry potter\n",
      "4415    harry potter chamber secret harry potter\n",
      "2       harry potter chamber secret harry potter\n",
      "0     harry potter halfblood prince harry potter\n",
      "615   harry potter halfblood prince harry potter\n",
      "[0.79398002 0.73513937 0.73513937 0.72475914 0.72475914]\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_vector, df_lem)[0]\n",
    "top5_idx = similarities.argsort()[-6:-1][::-1]  # top 5 (excluding itself)\n",
    "print(df.iloc[top5_idx])\n",
    "print(similarities[top5_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f9def5a-9784-4b0e-b11a-7ce52a37e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_vector = df_stem.iloc[4].values.reshape(1, -1)  # same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ce39278-e9a4-4cdf-bc79-6e65be9e26c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              text\n",
      "6             harry potter collection harry potter\n",
      "10674  harry potter philosopher stone harry potter\n",
      "4415      harry potter chamber secret harry potter\n",
      "2         harry potter chamber secret harry potter\n",
      "0       harry potter halfblood prince harry potter\n",
      "[0.81941012 0.75758536 0.74704024 0.74704024 0.73649198]\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_vector, df_stem)[0]\n",
    "top5_idx = similarities.argsort()[-6:-1][::-1]  # top 5 (excluding itself)\n",
    "print(df.iloc[top5_idx])\n",
    "print(similarities[top5_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bb292dc-9806-4b87-93ae-d9d25e5bcc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              text\n",
      "6             harry potter collection harry potter\n",
      "10674  harry potter philosopher stone harry potter\n",
      "4415      harry potter chamber secret harry potter\n",
      "2         harry potter chamber secret harry potter\n",
      "0       harry potter halfblood prince harry potter\n",
      "[0.81941012 0.75758536 0.74704024 0.74704024 0.73649198]\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_vector, df_stem)[0]\n",
    "top5_idx = similarities.argsort()[-6:-1][::-1]  # top 5 (excluding itself)\n",
    "print(df.iloc[top5_idx])\n",
    "print(similarities[top5_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66edd3cd-2407-4772-8513-2925b0d61cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(query_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3de11153-d335-4c2d-82d9-665459ff2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "model = Word2Vec.load(\"C:/Users/usame/Downloads/web2vec/word2vec_lemmatized_cbow_win2_dim100.model\")\n",
    "\n",
    "def get_avg_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "    \n",
    "query_vec = get_avg_vector(tokens, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c4a4a06-2886-46fd-8193-088777662229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "model = Word2Vec.load(\"C:/Users/usame/Downloads/web2vec/word2vec_lemmatized_cbow_win4_dim100.model\")\n",
    "\n",
    "def get_avg_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "    \n",
    "query_vec = get_avg_vector(tokens, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a8aaa1d-7dca-4ce1-9976-a91c739cd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "model = Word2Vec.load(\"C:/Users/usame/Downloads/web2vec/word2vec_lemmatized_cbow_win4_dim300.model\")\n",
    "\n",
    "def get_avg_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "    \n",
    "query_vec = get_avg_vector(tokens, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b13a45a-efd8-4cc8-b17f-675224a4fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "model = Word2Vec.load(\"C:/Users/usame/Downloads/web2vec/word2vec_lemmatized_cbow_win2_dim300.model\")\n",
    "\n",
    "def get_avg_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "    \n",
    "query_vec = get_avg_vector(tokens, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8dc64ab7-6950-4736-8ca3-dfc53903d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1cfe3f0-b94d-4c15-801e-4365d197e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_vecs = []\n",
    "for text in df[\"text\"]:\n",
    "    t = word_tokenize(text.lower())\n",
    "    corpus_vecs.append(get_avg_vector(t, model))\n",
    "\n",
    "# Cosine similarity\n",
    "sims = cosine_similarity([query_vec], corpus_vecs)[0]\n",
    "top5 = sims.argsort()[-6:-1][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b567c763-0053-4a38-929d-7dc9c6ce5478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query sentence:\n",
      "harry potter boxed set book harry potter\n",
      "\n",
      "Top 5 most similar sentences:\n",
      "- harry potter collection harry potter\n",
      "- harry potter chamber secret harry potter\n",
      "- harry potter chamber secret harry potter\n",
      "- harry potter la piedra filosofal harry potter\n",
      "- harry potter goblet fire harry potter\n"
     ]
    }
   ],
   "source": [
    "print(\"Query sentence:\")\n",
    "print(df.iloc[4][\"text\"]) \n",
    "\n",
    "print(\"\\nTop 5 most similar sentences:\")\n",
    "for i in top5:\n",
    "    print(f\"- {df.iloc[i]['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "770949da-6237-4d03-af17-54828cd6e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_sets = []\n",
    "\n",
    "for i in top5:\n",
    "    text = df.iloc[i][\"text\"]\n",
    "    tokens = word_tokenize(str(text).lower())  \n",
    "    top5_sets.append(set(tokens))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07c380df-d3ca-4801-b912-84b1d40b571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'potter', 'collection', 'harry'}, {'potter', 'secret', 'chamber', 'harry'}, {'potter', 'secret', 'chamber', 'harry'}, {'potter', 'piedra', 'filosofal', 'harry', 'la'}, {'potter', 'goblet', 'harry', 'fire'}]\n"
     ]
    }
   ],
   "source": [
    "print(top5_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfdd2500-dac8-46b5-8b43-7ed8f17a7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = df.iloc[4][\"text\"]\n",
    "query_set = set(word_tokenize(str(query_text).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b735b405-ab58-4611-81a5-f722a486d5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Top-1     Top-2     Top-3  Top-4     Top-5\n",
      "Query  0.333333  0.285714  0.285714   0.25  0.285714\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "query_text = df.iloc[4][\"text\"]  \n",
    "query_tokens = set(word_tokenize(str(query_text).lower()))\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union) if union else 0\n",
    "\n",
    "jaccard_scores = []\n",
    "for s in top5_sets:\n",
    "    score = jaccard_similarity(query_tokens, s)\n",
    "    jaccard_scores.append(score)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "matrix = pd.DataFrame(\n",
    "    [jaccard_scores],\n",
    "    index=[\"Query\"],\n",
    "    columns=[f\"Top-{i+1}\" for i in range(len(top5_sets))]\n",
    ")\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb7636-767d-489d-b33f-c87f1dd667e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
